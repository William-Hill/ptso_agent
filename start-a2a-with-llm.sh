#!/bin/bash

# Enhanced startup script for A2A agents with LLM configuration support

set -e

echo "ü§ñ Starting PTSO Agent A2A System with LLM Configuration"
echo "========================================================"

# Check if Docker and Docker Compose are installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please edit .env file with your API keys and LLM configuration."
fi

# Load environment variables
if [ -f .env ]; then
    export $(cat .env | grep -v '^#' | xargs)
fi

# LLM Configuration Menu
echo ""
echo "ü§ñ Choose your LLM configuration:"
echo "1) Commercial LLM (Gemini/OpenAI/Claude) - Default"
echo "2) Local LLM with Ollama"
echo "3) Local LLM with vLLM (GPU required)"
echo "4) Custom configuration"

read -p "Enter your choice (1-4): " llm_choice

case $llm_choice in
    1)
        echo "üîß Using Commercial LLM configuration..."
        export LLM_PROVIDER=gemini
        COMPOSE_PROFILES=""
        ;;
    2)
        echo "üîß Using Ollama local LLM..."
        export LLM_PROVIDER=ollama
        export OLLAMA_BASE_URL=http://ollama:11434
        COMPOSE_PROFILES="local-llm"
        ;;
    3)
        echo "üîß Using vLLM local LLM (GPU required)..."
        export LLM_PROVIDER=vllm
        export VLLM_BASE_URL=http://vllm:8000
        COMPOSE_PROFILES="local-llm"
        ;;
    4)
        echo "üîß Using custom configuration from .env file..."
        COMPOSE_PROFILES=""
        ;;
    *)
        echo "Invalid choice. Using default (Commercial LLM)"
        export LLM_PROVIDER=gemini
        COMPOSE_PROFILES=""
        ;;
esac

echo ""
echo "üöÄ Starting services with LLM provider: $LLM_PROVIDER"

# Build and start services
echo "üî® Building Docker images..."
if [ -n "$COMPOSE_PROFILES" ]; then
    docker-compose -f docker-compose-a2a.yml --profile $COMPOSE_PROFILES build
else
    docker-compose -f docker-compose-a2a.yml build
fi

echo "üöÄ Starting services..."
if [ -n "$COMPOSE_PROFILES" ]; then
    docker-compose -f docker-compose-a2a.yml --profile $COMPOSE_PROFILES up -d
else
    docker-compose -f docker-compose-a2a.yml up -d
fi

# Wait for services to be ready
echo "‚è≥ Waiting for services to start..."
sleep 15

# Check service health
echo "üè• Checking service health..."

# Check database
if docker-compose -f docker-compose-a2a.yml exec postgres pg_isready -U ptso_user -d ptso_db; then
    echo "‚úÖ Database is ready"
else
    echo "‚ùå Database is not ready"
fi

# Check LLM service if using local LLM
if [ "$LLM_PROVIDER" = "ollama" ]; then
    if curl -s http://localhost:11434/api/tags > /dev/null; then
        echo "‚úÖ Ollama service is ready"
    else
        echo "‚ùå Ollama service is not ready"
    fi
elif [ "$LLM_PROVIDER" = "vllm" ]; then
    if curl -s http://localhost:8000/v1/models > /dev/null; then
        echo "‚úÖ vLLM service is ready"
    else
        echo "‚ùå vLLM service is not ready"
    fi
fi

# Check weather agent
if curl -s http://localhost:8001/health > /dev/null; then
    echo "‚úÖ Weather Agent is ready"
else
    echo "‚ùå Weather Agent is not ready"
fi

# Check wardrobe agent
if curl -s http://localhost:8002/health > /dev/null; then
    echo "‚úÖ Wardrobe Agent is ready"
else
    echo "‚ùå Wardrobe Agent is not ready"
fi

# Check PTSO agent
if curl -s http://localhost:8000/health > /dev/null; then
    echo "‚úÖ PTSO Agent is ready"
else
    echo "‚ùå PTSO Agent is not ready"
fi

echo ""
echo "üéâ A2A Agent System is running!"
echo ""
echo "üìä Service URLs:"
echo "  ‚Ä¢ PTSO Agent (Main):     http://localhost:8000"
echo "  ‚Ä¢ Weather Agent:         http://localhost:8001"
echo "  ‚Ä¢ Wardrobe Agent:        http://localhost:8002"
echo "  ‚Ä¢ Database:              localhost:5432"

if [ "$LLM_PROVIDER" = "ollama" ]; then
    echo "  ‚Ä¢ Ollama LLM:            http://localhost:11434"
elif [ "$LLM_PROVIDER" = "vllm" ]; then
    echo "  ‚Ä¢ vLLM LLM:              http://localhost:8000"
fi

echo ""
echo "üîç Health Checks:"
echo "  ‚Ä¢ PTSO Agent Health:     http://localhost:8000/health"
echo "  ‚Ä¢ Weather Agent Health:  http://localhost:8001/health"
echo "  ‚Ä¢ Wardrobe Agent Health: http://localhost:8002/health"

if [ "$LLM_PROVIDER" = "ollama" ]; then
    echo "  ‚Ä¢ Ollama Health:         http://localhost:11434/api/tags"
elif [ "$LLM_PROVIDER" = "vllm" ]; then
    echo "  ‚Ä¢ vLLM Health:           http://localhost:8000/v1/models"
fi

echo ""
echo "üí¨ Test the system:"
echo "  curl -X POST http://localhost:8000/ask -H 'Content-Type: application/json' -d '{\"message\": \"What should I wear in Atlanta today?\"}'"
echo ""
echo "üß™ Run comprehensive tests:"
echo "  python test-a2a-agents.py"
echo ""
echo "üõë To stop the system:"
if [ -n "$COMPOSE_PROFILES" ]; then
    echo "  docker-compose -f docker-compose-a2a.yml --profile $COMPOSE_PROFILES down"
else
    echo "  docker-compose -f docker-compose-a2a.yml down"
fi
